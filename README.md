# `Welcome, Palantir`

**Curated Repository Hub for Frontier Alignment & Interpretability Collaboration**

Welcome to a joint repository index from two aligned GitHub profiles — each contributing unique value to operational safety engineering and interpretability-focused research at scale.



##  David Kim — Interpretability & Field Research

[GitHub Profile → davidkimai](https://github.com/davidkimai)

This profile hosts structured, research-driven repositories focusing on model transparency, QK/OV attribution mapping, safety-informed system prompting, and cognitive model introspection. Select highlights include:

### Core Research Modules
- [Symbolic-Interpretability](https://github.com/davidkimai/Symbolic-Interpretability)  
  A foundational ontology for understanding transformer cognition through symbolic structures.
- [Recursive-Interpretability-Core](https://github.com/davidkimai/Recursive-Interpretability-Core)  
  Probes model collapse, attribution gaps, and emergent reasoning failure points.
- [Rediscovering-Interpretability](https://github.com/davidkimai/Rediscovering-Interpretability)  
  Re-evaluates assumptions in post-hoc analysis with accessible design and case studies.

### Attribution Testing Infrastructure
- [Claude-QKOV-Attributions](https://github.com/davidkimai/claude-qkov-attributions)  
- [ChatGPT-QKOV-Attributions](https://github.com/davidkimai/chatgpt-qkov-attributions)  
- [Gemini / Grok / DeepSeek Attributions](https://github.com/davidkimai/deepseek-qkov-attributions)

### Concept & Safety Case Studies
- [Model Welfare](https://github.com/davidkimai/model-welfare)  
  Safety implications for increasingly agentic models.
- [NeurIPS Submission: Emergent Field Architecture](https://github.com/davidkimai/NeurIPS-Submission-Case-Study)  
- [Reverse-Turing Benchmarking](https://github.com/davidkimai/reverse-turing)  



##  Caspian Keyes — Operational Alignment & Systems Engineering

[GitHub Profile → caspiankeyes](https://github.com/caspiankeyes)

This profile focuses on tooling, red-team frameworks, diagnostic pipelines, and integrations to accelerate transparency, model debugging, and institutional safety workflows.

### Core Diagnostic Frameworks
- [Symbolic-Residue](https://github.com/caspiankeyes/Symbolic-Residue)  
  Detects silent failure modes and attribution voids across model behavior.
- [transformerOS](https://github.com/caspiankeyes/transformerOS)  
  Modular architecture for transformer model inspection, introspection, and testing.
- [recursionOS](https://github.com/caspiankeyes/recursionOS)  
  Infrastructure for distributed interpretability workflows.

### Adversarial Testing & Model Evaluation
- [AISecForge](https://github.com/caspiankeyes/AISecForge-Advanced-AI-Security-Testing)  
- [AART: Adversarial Research Toolkit](https://github.com/caspiankeyes/AART-AI-Adversarial-Research-Toolkit)  
- [FRAME: Recursive Evaluation Infrastructure](https://github.com/caspiankeyes/FRAME-arXiv-Publication)

### Frontier Lab Alignment Case Studies
- [Anthropic Institutional Audits](https://github.com/caspiankeyes/Epistemic-Audit-Anthropic-Case-Study)  
- [OpenAI / DeepMind Integration Modules](https://github.com/caspiankeyes/OpenAI-Integrations)  
- [Claude Internal Tracing](https://github.com/caspiankeyes/Claude-QKOV-Trace)



##  Key Joint Repositories & Resources

| Focus Area | Repository |
|||
| Cross-Agent Testing | [qkov-cross-agent-testing](https://github.com/caspiankeyes/qkov-cross-agent-testing) |
| Attributions Index | [Symbolic Interpretability](https://github.com/davidkimai/Symbolic-Interpretability) |
| Infrastructure Modules | [pareto-lang](https://github.com/caspiankeyes/pareto-lang) |
| Translator Layers | [universal-translator](https://github.com/davidkimai/universal-translator) |
| Alignment Tools | [Claude-Self-Audit-Proof](https://github.com/caspiankeyes/Claude-Self-Audit-Proof) |
| Structured Expression | [The Structure Behind Self Expression](https://github.com/davidkimai/The-Structure-Behind-Self-Expression) |



##  Contact + Collaboration Path

We welcome inquiry, contribution, or internal review dialogue. Both profiles reflect our intention to support robust, transparent, safety-forward AI development—built in the open and intended for integration.

- David Kim → recursive.davidkim@pm.me  
- Caspian Keyes → (contact via GitHub or internal channel)



**Thank you for reviewing. We’re excited to support and collaborate with Palantir’s safety, engineering, and research teams.**


